# Investigaci√≥n T√©cnica: Despliegue de Servidores Web de Alto Rendimiento con Nginx y Docker

## Metadata de Investigaci√≥n
- **Fecha**: 10 de febrero de 2026
- **Tema**: Implantaci√≥n y Administraci√≥n de Servidor Web con Docker
- **Enfoque**: Arquitectura interna, casos de uso reales, seguridad y alto rendimiento

---

## M√ìDULO 1: FUNDAMENTOS DEL SERVICIO WEB

Antes de desplegar un servidor web o configurarlo, necesitamos entender **qu√© es**, **c√≥mo se comunica con los clientes** y **por qu√© elegimos uno u otro**. Este m√≥dulo cubre los fundamentos: el protocolo HTTP, la evoluci√≥n de sus versiones, el panorama actual de servidores web, y por qu√© Nginx se ha convertido en la opci√≥n dominante para sitios de alto tr√°fico.

---

### 1.1 ¬øQu√© es un Servidor Web?

Un **servidor web** tiene dos componentes:

- **Hardware**: La m√°quina f√≠sica o virtual (CPU, RAM, disco, red) que aloja el servicio
- **Software (Daemon)**: El programa que escucha peticiones en los puertos 80 (HTTP) y 443 (HTTPS) y responde con p√°ginas web, archivos o datos

Ejemplos de software servidor: **Nginx**, **Apache HTTP Server**, **IIS** (Microsoft), **LiteSpeed**.

#### Flujo b√°sico: ¬øC√≥mo funciona?

| # | Origen | Direcci√≥n | Destino | Acci√≥n | Detalle |
|:-:|:------:|:---------:|:-------:|:-------|:--------|
| **1** | üßë‚Äçüíª Navegador | ‚û°Ô∏è | üñ•Ô∏è Servidor | **Petici√≥n** | `GET /index.html` (Solicita recurso) |
| **2** | üñ•Ô∏è Servidor | ‚öôÔ∏è | üñ•Ô∏è Servidor | **Proceso** | Busca archivo, ejecuta c√≥digo, consulta BD |
| **3** | üñ•Ô∏è Servidor | ‚¨ÖÔ∏è | üßë‚Äçüíª Navegador | **Respuesta** | `HTTP 200 OK` + Archivo HTML |
| **4** | üßë‚Äçüíª Navegador | üëÅÔ∏è | üßë‚Äçüíª Usuario | **Visualizaci√≥n** | Renderiza el HTML/CSS/JS |

**En resumen**: el navegador **pide** (petici√≥n HTTP), el servidor **busca** y **responde** (respuesta HTTP). Todo el protocolo HTTP que veremos a continuaci√≥n define las reglas de esta conversaci√≥n.

---

### 1.2 El Protocolo HTTP/S

#### Definici√≥n T√©cnica
HTTP (Hypertext Transfer Protocol) es un protocolo de capa de aplicaci√≥n (Capa 7 OSI) basado en el modelo cliente-servidor que utiliza TCP como transporte.

#### M√©todos HTTP Principales
- **GET**: Solicita un recurso (idempotente, cacheable)
- **POST**: Env√≠a datos al servidor (no idempotente)
- **PUT**: Actualiza/crea un recurso (idempotente)
- **DELETE**: Elimina un recurso (idempotente)
- **HEAD**: Solicita headers sin body
- **OPTIONS**: Consulta m√©todos soportados
- **PATCH**: Modificaci√≥n parcial

#### C√≥digos de Estado HTTP

**2xx - √âxito**
- `200 OK`: Petici√≥n exitosa
- `201 Created`: Recurso creado
- `204 No Content`: √âxito sin contenido de respuesta

**3xx - Redirecci√≥n**
- `301 Moved Permanently`: Redirecci√≥n permanente
- `302 Found`: Redirecci√≥n temporal
- `304 Not Modified`: Recurso no modificado (cach√© v√°lida)

**4xx - Error del Cliente**
- `400 Bad Request`: Sintaxis inv√°lida
- `401 Unauthorized`: Autenticaci√≥n requerida
- `403 Forbidden`: Sin permisos
- `404 Not Found`: Recurso no existe
- `429 Too Many Requests`: Rate limiting aplicado

**5xx - Error del Servidor**
- `500 Internal Server Error`: Error gen√©rico del servidor
- `502 Bad Gateway`: Proxy recibi√≥ respuesta inv√°lida del upstream
- `503 Service Unavailable`: Servidor temporalmente no disponible
- `504 Gateway Timeout`: Timeout del upstream

#### Cabeceras HTTP Cr√≠ticas

**Cabeceras de Petici√≥n**:
```http
Host: ejemplo.com
User-Agent: Mozilla/5.0...
Accept: text/html,application/json
Accept-Encoding: gzip, deflate, br
Connection: keep-alive
Authorization: Bearer <token>
```

**Cabeceras de Respuesta**:

```http
Content-Type: application/json; charset=utf-8
Content-Length: 1234
Cache-Control: max-age=3600
Set-Cookie: session_id=abc123; Secure; HttpOnly
X-Frame-Options: DENY
```


---

### 1.3 Evoluci√≥n del Protocolo HTTP

#### HTTP/1.1 (1997 - RFC 2616, actualizado RFC 7230-7235)

**Caracter√≠sticas**:

- **Keep-Alive (Persistent Connections)**: Reutilizaci√≥n de conexiones TCP
- **Pipelining**: Env√≠o de m√∫ltiples peticiones sin esperar respuestas (poco usado por head-of-line blocking)
- **Chunked Transfer Encoding**: Permite transmisi√≥n sin conocer longitud total
- **Host Header**: Soporte para virtual hosts

**Limitaciones**:

- Una petici√≥n a la vez por conexi√≥n (sin multiplexaci√≥n)
- Headers en texto plano (overhead)
- Head-of-Line Blocking en TCP

**Implementaci√≥n Nginx**:

```nginx
http {
    keepalive_timeout 65;      # 65 segundos de Keep-Alive
    keepalive_requests 100;    # M√°ximo 100 peticiones por conexi√≥n
}
```


---

#### HTTP/2 (2015 - RFC 7540)

**Caracter√≠sticas Clave**:

1. **Multiplexaci√≥n Binaria**:
    - M√∫ltiples streams en una √∫nica conexi√≥n TCP
    - Frame-based protocol (binario, no texto)
    - Elimina head-of-line blocking a nivel de aplicaci√≥n
2. **Compresi√≥n de Headers (HPACK)**:
    - Reduce overhead de headers repetitivos
    - Tabla de indexaci√≥n din√°mica
3. **Server Push**:
    - Servidor env√≠a recursos proactivamente
    - Reduce latencia en recursos cr√≠ticos
4. **Priorizaci√≥n de Streams**:
    - Dependencias y pesos para optimizar carga

**Limitaciones**:

- Sigue usando TCP: head-of-line blocking a nivel de transporte
- Si se pierde un paquete TCP, todos los streams se bloquean

**Configuraci√≥n Nginx HTTP/2**:

```nginx
server {
    listen 443 ssl http2;
    ssl_certificate /etc/ssl/certs/cert.pem;
    ssl_certificate_key /etc/ssl/private/key.pem;
    
    # Server push
    http2_push /css/styles.css;
    http2_push /js/app.js;
}
```


---

#### HTTP/3 (2022 - RFC 9114) + QUIC

**Definici√≥n**: HTTP/3 es el mapeo de sem√°ntica HTTP sobre el protocolo de transporte QUIC (RFC 9000), que usa UDP en lugar de TCP.

**QUIC (Quick UDP Internet Connections)**:

- **Capa de transporte sobre UDP** (puerto 443)
- **TLS 1.3 integrado nativamente** en el transporte
- **Multiplexaci√≥n sin head-of-line blocking**: p√©rdida de paquete afecta solo a un stream
- **Connection migration**: cambio de IP/red sin reiniciar conexi√≥n (identificadores de conexi√≥n)

**Ventajas HTTP/3**:

1. **Handshake m√°s r√°pido**:
    - HTTP/2 sobre TCP+TLS: 2-3 RTT (Round Trip Time)
    - HTTP/3 sobre QUIC: 1 RTT (0-RTT para conexiones repetidas)
2. **Eliminaci√≥n de head-of-line blocking**:
    - P√©rdida de paquetes no bloquea otros streams
3. **Mejor rendimiento en redes m√≥viles**:
    - Connection migration al cambiar de WiFi a 4G/5G

**Stack Comparison**:

| Capa | üê¢ HTTP/1.1 & HTTP/2 | üöÄ HTTP/3 (QUIC) |
|:----:|:--------------------:|:----------------:|
| **Aplicaci√≥n** | HTTP/2 (Streams) | HTTP/3 (Streams) |
| **Seguridad** | TLS 1.2 / 1.3 (capa separada) | **TLS 1.3** (Integrado en QUIC) |
| **Transporte** | **TCP** (Fiable, lento por handshake) | **QUIC** (UDP + Fiabilidad por software) |
| **Red** | IP | IP |

> **Gran diferencia**: HTTP/3 elimina el handshake TCP redundante y el "head-of-line blocking" al mover la fiabilidad a QUIC (sobre UDP).

**Configuraci√≥n Nginx HTTP/3 (Nginx 1.25+)**:

```nginx
server {
    listen 443 quic reuseport;          # QUIC/HTTP3
    listen 443 ssl http2;               # Fallback HTTP/2
    
    ssl_protocols TLSv1.3;              # TLS 1.3 obligatorio
    ssl_certificate /etc/ssl/cert.pem;
    ssl_certificate_key /etc/ssl/key.pem;
    
    # Anunciar HTTP/3 v√≠a header Alt-Svc
    add_header Alt-Svc 'h3=":443"; ma=86400';
    
    quic_retry on;                      # Protecci√≥n anti-DDoS
    ssl_early_data on;                  # 0-RTT resumption
}
```

> [!IMPORTANT]
> **Nota cr√≠tica para Docker**: HTTP/3 utiliza **UDP**, no TCP. Al dockerizar, es **obligatorio** mapear el puerto expl√≠citamente como UDP o no funcionar√°:
> ```yaml
> ports:
>   - "443:443/tcp"   # HTTPS/2
>   - "443:443/udp"   # HTTP/3 (QUIC) ¬°Vital!
> ```

**Adopci√≥n 2026**:

- Chrome, Firefox, Edge, Safari soportan HTTP/3
- ~40% del tr√°fico web global usa HTTP/3 (Cloudflare, Google, Facebook)

---

### 1.4 Mercado de Servidores Web (2025-2026)

#### Datos de Netcraft (Mayo 2025)

| Servidor | Mayo 2025 | % Market Share | Cambio |
| :-- | :-- | :-- | :-- |
| **Nginx** | 259,608,513 | **21.15%** | +0.37pp |
| **Apache** | 187,533,263 | **15.28%** | -0.15pp |
| **Cloudflare** | 197,436,000 | ~16% | +0.04pp |
| **LiteSpeed** | 57,000,000 | ~4.6% | Creciendo |

#### Sitios de Alto Tr√°fico (Top 1M)

| Servidor | Mayo 2025 | % Share |
| :-- | :-- | :-- |
| **Nginx** | 5,516,359 | 40.95% |
| **Apache** | 3,069,468 | 22.79% |

**Tendencias**:

- Nginx domina en sitios de **alto tr√°fico** (>1M visitas/mes)
- Apache mantiene presencia en hosting compartido y aplicaciones legacy
- Cloudflare Server (fork de Nginx) gana terreno en CDN
- LiteSpeed crece en hosting web por soporte nativo de HTTP/3 y Quic

**Por qu√© Nginx domina el alto tr√°fico**:

1. Arquitectura event-driven (mayor concurrencia)
2. Menor footprint de memoria (~2.5MB vs ~10MB Apache)
3. Proxy reverso m√°s eficiente
4. Mejor rendimiento sirviendo contenido est√°tico

---

### 1.5 Arquitectura Nginx: Modelo Event-Driven

#### Definici√≥n T√©cnica

Nginx utiliza una **arquitectura as√≠ncrona, no-bloqueante, basada en eventos** (event-driven) en lugar del modelo tradicional de un proceso/thread por conexi√≥n.

#### Comparaci√≥n: Apache vs Nginx



**Apache (MPM Prefork/Worker)**:

```mermaid
graph TD
    Master[Apache Master Process] -->|Inicia| W1[Worker Process/Thread]
    Master -->|Inicia| W2[Worker Process/Thread]
    Master -->|Inicia| W3[Worker Process/Thread]
    
    W1 -->|Atiende| C1[Connection 1]
    W2 -->|Atiende| C2[Connection 2]
    W3 -->|Atiende| C3[Connection 3]
```

- **1 thread/proceso = 1 conexi√≥n**
- Consume ~3-5MB RAM por worker
- Context switching costoso con miles de conexiones

**Nginx (Event-Driven)**:

```mermaid
graph TD
    Master[Master Process] -->|Gesti√≥n/Se√±ales| W1[Worker 1]
    Master -->|Gesti√≥n/Se√±ales| W2[Worker 2]
    Master -->|Gesti√≥n/Se√±ales| WN[Worker N]
    
    subgraph EventLoop [Worker 1 Event Loop]
        W1 -->|Maneja| C[Conexiones 1..1000+]
    end
```

- **1 worker = miles de conexiones**
- Worker single-threaded, pinned a CPU
- Event loop con epoll/kqueue (Linux/BSD)


#### Funcionamiento del Event Loop

**Analog√≠a**: Imagina un **recepcionista de hotel**:

- **Modelo Apache** (1 recepcionista por cliente): Cada hu√©sped tiene su propio recepcionista asignado. Si un recepcionista espera a que alguien rellene un formulario, no puede atender a nadie m√°s. Con 1.000 hu√©spedes, necesitas 1.000 recepcionistas ‚Üí costoso.

- **Modelo Nginx** (1 recepcionista para todos): Un solo recepcionista atiende a muchos hu√©spedes. Mientras uno rellena el formulario, atiende a otro. Cuando el primero termina, vuelve a √©l. Con 1.000 hu√©spedes, 1 recepcionista eficiente es suficiente ‚Üí r√°pido y econ√≥mico.

Esto es exactamente lo que hace el **event loop** de Nginx: un worker atiende miles de conexiones alternando entre ellas seg√∫n qui√©n tenga datos listos para procesar.

**Ciclo del Event Loop (simplificado)**:

```mermaid
graph TD
    A[Inicio: Servidor Encendido] --> B{1. Esperar eventos}
    B -- ¬øDatos listos? --> C[2. Procesar conexi√≥n]
    
    C --> D{Tipo de evento}
    D -- Petici√≥n Cliente --> E[Leer petici√≥n]
    D -- Respuesta Backend --> F[Reenviar]
    D -- Listo para escribir --> G[Enviar HTML]
    
    E --> H[3. Volver al inicio]
    F --> H
    G --> H
    H --> B
```

**Flujo de una petici√≥n HTTP**:

1. Leer petici√≥n
2. Procesar
3. Consultar backend (si es necesario)
4. Enviar respuesta
5. Mantener conexi√≥n o cerrar


#### Ventajas del Modelo Event-Driven

1. **Alta Concurrencia (C10k problem solved)**:
    - 10,000+ conexiones simult√°neas con < 100MB RAM
    - Apache requiere GB de RAM para lo mismo
2. **Bajo consumo de CPU**:
    - Sin context switching entre threads
    - Worker pinned a CPU core
3. **Predecibilidad**:
    - Consumo de recursos lineal con el n√∫mero de workers (no con conexiones)
4. **Eficiencia en I/O**:
    - No bloquea en operaciones lentas (disco, upstream)

#### Configuraci√≥n Nginx Workers

```nginx
# Nginx.conf
worker_processes auto;  # 1 worker por CPU core
worker_cpu_affinity auto;  # Pin workers a CPU cores espec√≠ficos

events {
    worker_connections 4096;  # M√°x conexiones por worker
    use epoll;                # Event mechanism (Linux)
    multi_accept on;          # Acepta m√∫ltiples conexiones a la vez
}
```

**C√°lculo de conexiones m√°ximas**:

```
Max Connections = worker_processes √ó worker_connections
```

Ejemplo: 4 cores √ó 4096 conexiones = 16,384 conexiones simult√°neas

---

### 1.6 Ventajas de Nginx

#### 1. Rendimiento (Performance)

**Benchmarks t√≠picos**:

- **Contenido est√°tico**: 50,000-100,000 req/s en hardware moderno
- **Proxy reverso**: 10,000-30,000 req/s dependiendo de backend
- **Latencia**: sub-milisegundo para recursos est√°ticos en cach√©

**Comparaci√≥n con Apache**:

- Nginx: 2x-4x m√°s r√°pido sirviendo est√°ticos
- Nginx: 3x-5x mayor throughput en proxy reverso


#### 2. Bajo Consumo de RAM (Memory Footprint)

**Footprint t√≠pico**:

- Master process: ~2-3 MB
- Worker process: ~2-5 MB base + (conexiones √ó ~1KB)
- Total t√≠pico: 50-200 MB para 10,000 conexiones

**Apache equivalente**: 500-1500 MB para la misma carga

#### 3. Escalabilidad Horizontal y Vertical

**Vertical**: A√±adir m√°s cores = a√±adir m√°s workers (lineal)
**Horizontal**: M√∫ltiples instancias detr√°s de load balancer

#### 4. Versatilidad

- Servidor web est√°tico
- Proxy reverso (HTTP, WebSocket, gRPC)
- Load balancer (L7)
- Proxy de cach√©
- Terminaci√≥n SSL/TLS


#### 5. Configuraci√≥n Declarativa

Archivos de configuraci√≥n legibles y modularizables (no requiere recompilaci√≥n).

---
